In the face of the ongoing exponential data growth, the pressing questions arise: How can we read and write this increasing volume efficiently? Furthermore, how can we ensure the availability and reliability of this stored data? Inspired by these questions, my present research is dedicated to systems that address these challenges. 

Looking back at my undergraduate studies, a comprehensive curriculum introduced me to the captivating domain of distributed systems. As part of the assignment, I worked on a simple word count problem using Hadoop (HDS and MapReduce).  Observing the harmony and coordination among these interconnected systems as they solve complex problems has sparked my passion. Motivated by a growing curiosity, I found myself navigating the details of Hadoop's inner workings, immersing deeply into the foundational papers that shaped its evolution—specifically, works on the Google File System and MapReduce. This exploration shifted me towards researching large-scale storage and processing systems. 

While pursuing my undergraduate degree, I had the opportunity to research horizontal auto-scaling of cloud infrastructure. Firstly, I discovered that many small businesses went online and started using cloud infrastructure during the COVID-19 lockdown. Still, most cloud providers didn’t provide proactive auto-scaling for all resources, and reactive scaling was challenging to manage for them. So, during my thesis, I led a team of two to work on proactive auto-scaling of cloud resources. We explored the publicly available web traces of websites, such as NASA and Wikipedia, and noticed a web usage pattern. Based on our observation, we designed a heuristic algorithm based on exponential smoothing to predict the pattern using system usage logs. Then, we designed a system consisting of five interconnected services based on the MAPE loop. They perform the required steps, such as collecting, storing, and analyzing the system logs and planning and executing the scaling decision. Segregation of the services provided us the options to run them on the optimized devices, such as running the analyzer on GPU or keeping the logs cache near the analyzer. This research led to a peer-reviewed journal paper titled An event-driven and lightweight proactive auto-scaling architecture for cloud applications. This architecture scales resources proactively based on real-time demand patterns, achieving cost efficiency, a seamless user experience, a smaller memory footprint, and low CPU usage.

During my tenure as an R&D software engineer at Cefalo, I worked on a project, Spenn, which provides blockchain-based free mobile banking services across Africa. On top of the blockchain layer, partitioned databases acted as a global state for the blockchain ledger. This setup posed a risk of inconsistency because updates needed to be made in multiple places during an operation, both in the databases and blockchain. In the realm of financial technology applications, maintaining atomicity, consistency, and isolation is crucial. I played a part in addressing this challenge by exploring database transaction mechanisms and weighing their advantages and disadvantages. In the end, my choice leaned towards the saga transaction mechanism. Its long-running and non-blocking nature aligns well with blockchain's inherent time-consuming aspects, particularly in verifying and incorporating new operations. Consequently, this contribution ensured eventual consistency at the expected level. Otherwise, this could result in a lack of trust in the reliability of our service, hindering its adoption among African users.

All my experiences collectively shaped my research interests and motivated me to pursue graduate studies. In preparation, I am currently doing a hands-on system design of a storage system focusing on enhancing the read-write performance in pluggable storage engines. I am experimenting with various data structures, compression algorithms, and memory for these storage systems. Moreover, I am looking into ensuring consistency and fault tolerance when these storage engines are deployed in heterogeneous multi-master systems environments.

Furthermore, I had the privilege of contributing as one of the problem setters and judges in the esteemed SUST Inter-University Programming Contest. While authoring and reviewing the problems,  I embraced the challenge of articulating them in a manner that allows contestants to understand the problem in the blink of an eye and invest their whole time in solving the problem. Besides, I also got an opportunity to take on the role of a trainer for Fresher Software Engineers at Cefalo, where my approach involved simplifying complex concepts, fostering comprehensive knowledge sharing, and progressively presenting them with real-world problems of escalating difficulty levels.

The University of Texas Arlington’s robust research program and Lab support in this field seem tailor-made for my goal. ACES, DBXLAB, and Adaptive and Scalable Systems LAB can provide the perfect and cherished environment to collaborate with distinguished professors and peers who share my passion. Their past and current work indicates its members’ unique strengths in this field. I would be excited to work with Song Jiang, Hui Lui, Jia Rao, and Huang Jong. Specifically, Song Jiang has made outstanding contributions to storage research, especially in his recent work TurboHash,  enhancing the scalability and reducing the search scope of a hash table. The sharding mechanism discussed in this work is captivating to me due to its utilization of  256B PMEM access. My research interests also considerably overlap with Hui Lu and Jia Rao’s work, such as P2CACHE, where they introduced an efficient buffering mechanism for well-tested kernel file systems to leverage persistent memory (PM). I found it fascinating since it doesn't require any modifications to applications or kernel systems but provide fast read and write performance on kernel file system. 

After graduate studies, I aim to pursue a career in academia so that I can continue to develop research to address these challenges and more. I also hope that my research will play a role in shaping the future of information technology, paving the way for innovative applications and services reliant on vast amounts of data. Pursuing further education at the University of Texas Arlington would be a significant stride toward achieving this goal.
